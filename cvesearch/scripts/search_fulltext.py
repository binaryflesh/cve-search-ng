#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Search the CVE full text database
#
# Software is free software released under the "GNU Affero General Public License v3.0"
#
# Copyright (c) 2012-2019  Alexandre Dulaunoy - a@foo.be
# Copyright (c) 2015-2019  Pieter-Jan Moreels - pieter-jan@pidgey.net

# Imports
import sys
from json import dumps
from bson import json_util

try:
    from whoosh import index, qparser
    from whoosh.fields import Schema, TEXT, ID
    from whoosh.qparser import QueryParser
    from nltk.stem.wordnet import WordNetLemmatizer
    from nltk.corpus import stopwords
except ImportError:
    sys.exit(-1)

from . import _search, pass_context, STRING, INT, BOOL
from .. import Configuration, DatabaseLayer


@_search.command('fulltext')
@pass_context
@_search.argument('-q', '--query', type=STRING, multi=True)
@_search.option('-o/-a', '--or/--and', type=BOOL, default=False)
@_search.option('-t', '--title', type=STRING, default=False)
@_search.option('-f', '--json', type=BOOL, default=False)
@_search.argument('-m', '--frequency', type=INT, default=False)
@_search.argument('-l', '--dump', type=BOOL, default=False)
@_search.argument('-g', '--graph', type=BOOL, default=False)
@_search.option('-s', '--stemming', type=BOOL, default=False)
@_search.option('-n', '--name', type=BOOL, default=False)
@_search.option('-r', '--ranking', type=BOOL, default=False)
def search_fulltext(query, or_and, title, o_json, freq, dump, graph, stem, name, ranking):
    """Full text search from cve-search.

    :param query: query to lookup (one or more)
    :param or_and: OR of the query to lookup (default=AND)
    :param title: output title of the matching CVEs
    :param o_json: output matching CVEs in JSON
    :param freq: most frequent terms in CVE description
    :param dump: dump all terms encountered in CVE description
    :param graph: graph of most frequent terms with each matching CVE (JSON output)
    :param stem: enable stemming on graph JSON output (default is False)
    :param name: lookup complete cpe (Common Platform Enumeration) name for vulnerable configuration
    :param ranking: lookup ranking of vulnerable configuration
    :return:
    """

    indexpath = Configuration.getIndexdir()
    db = None
    schema = Schema(title=TEXT(stored=True), path=ID(stored=True), content=TEXT)

    ix = index.open_dir(indexpath)

    if freq or title:
        db = DatabaseLayer()

    if query:
        with ix.searcher() as searcher:
            if not or_and:
                query = QueryParser("content", ix.schema).parse(" ".join(query))
            else:
                query = QueryParser("content", schema=ix.schema, group=qparser.OrGroup).parse(" ".join(query))

        results = searcher.search(query, limit=None)
        for x in results:
            if not o_json:
                _search.echo(x['path'])
            else:
                cve = db.CVE.get(x['path'], ranking=ranking)
                data = cve.dict(human_dates=True)
                if ranking:
                    data['ranking'] = list(cve.ranking)
                if name:
                    data['vulnerable_configuration'] = [x.title for x in cve.vulnerable_configuration]
                _search.echo(f'{dumps(data, sort_keys=True, default=json_util.default)}')
            if title and not freq:
                _search.echo(" -- " + x['title'])
    elif freq:
        xr = ix.searcher().reader()
        for x in xr.most_frequent_terms("content", number=freq):
            _search.echo(f'{int(x[0])},{x[1].decode("utf-8")}\n')
    elif dump and not graph:
        xr = ix.searcher().reader()
        for x in xr.lexicon("content"):
            _search.echo(x)
    elif graph:
        lmtzr = None
        if stem:
            lmtzr = WordNetLemmatizer()
        xr = ix.searcher().reader()
        s = {"name": 'cve-search', "children": []}
        d = {}
        for x in xr.most_frequent_terms("content", 3000):
            q = QueryParser("content", ix.schema).parse(x[1])
            if stem:
                term = lmtzr.lemmatize(x[1].decode('utf-8'), 'v')
                if term in stopwords.words('english'):
                    continue
            else:
                term = x[1]
                term = term.decode('utf-8')
            if term in d:
                d[term]['size'] = d[term]['size'] + int(x[0])
            else:
                d[term] = {}
                d[term]['size'] = int(x[0])
        for k in sorted(d.keys(), key=lambda y: (d[y]['size']), reverse=True):
            v = {}
            v["name"] = k
            v["size"] = d[k]['size']
            s['children'].append(v)
        _search.echo(f'{dumps(s, indent=4)}')


if __name__ == '__main__':
    search_fulltext(input)